{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These benchmarks are based off of those of [Adversarial-Attacks-PyTorch](https://github.com/Harry24k/adversarial-attacks-pytorch/blob/master/README.md#performance-comparison). However, they differ in that:\n",
    "- They ensure that all enqueued asynchornous CUDA computations have been completed prior to recording the time elapsed\n",
    "- [Madry lab models](https://github.com/mit-ll-responsible-ai/responsible-ai-toolbox/blob/dab4ba8b506ad6bd83842a282f3867388896ce65/experiments/src/rai_experiments/models/pretrained.py#L59-L69) are used for timing instead of robust_bench (I hit a `SSLCertVerificationError` when trying to download the `robust_bench` models)\n",
    "- Only FGSM, Linf PGD, and L2 PGD are timed (rai-toolbox doesn't have the other methods yet)\n",
    "- Time per-step is recorded for easier comparison across methods\n",
    "\n",
    "\n",
    "Depenencies:\n",
    "- torch\n",
    "- [rai-toolbox](https://mit-ll-responsible-ai.github.io/responsible-ai-toolbox/#installation)\n",
    "- [rai-experiments](https://github.com/mit-ll-responsible-ai/responsible-ai-toolbox/tree/main/experiments#installing-rai-experiments-utilities)\n",
    "- [torch-attacks](https://github.com/Harry24k/adversarial-attacks-pytorch/blob/master/README.md#hammer-installation)\n",
    "- [foolbox](https://github.com/bethgelab/foolbox#-quickstart)\n",
    "- [ART](https://github.com/Trusted-AI/adversarial-robustness-toolbox/wiki/Get-Started#installation-with-pip) (with the `pytorch` dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from contextlib import contextmanager\n",
    "from functools import wraps\n",
    "from time import time\n",
    "from typing import Callable, Hashable, Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "__all__ = [\"PyTorchTimeLogger\"]\n",
    "\n",
    "\n",
    "class PyTorchTimeLogger(defaultdict):\n",
    "    \"\"\"Provides a context manager and decorator for timing the code within the\n",
    "    context. Measurements are in seconds. \n",
    "    \n",
    "    This ensures that CUDA-bound computations in PyTorch\n",
    "    are timed appropriately. Specifically, the default device \n",
    "    stream in synchronized so that all enqueued asynchornous CUDA \n",
    "    computations have been completed prior to recording the time elapsed.\n",
    "    \n",
    "    This is a subclass of `defaultdict`, and stores the mappings:\n",
    "    \n",
    "        event-name (str) -> sequence of associated times (List[float])\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Timing an event with a context manager\n",
    "\n",
    "    >>> timelog = PyTorchTimeLogger()\n",
    "    >>> with timelog.timeit(name=\"event-1\", cpu_only=False)\n",
    "    ...    # Timing of this context will be appended\n",
    "    ...    # to the list `timelog[\"event-1\"]`\n",
    "    ...    # Times are in seconds\n",
    "\n",
    "    Timing function execution with a decorator\n",
    "\n",
    "    >>> @timelog  # you can specify `name` and `cpu_only` if you'd like\n",
    "    ... def func():\n",
    "    ...    # Time spent within function body will be logged to\n",
    "    ...    # `timelog[\"func\"]`\n",
    "    ...    pass\n",
    "\n",
    "    Or, you can make a timed function \"on the fly\" with a functional form factor\n",
    "\n",
    "    >>> def f(x): return x\n",
    "    >>> # timing in f will be logged to `timelog[\"special-name-for-f\"]`\n",
    "    >>> timed_f = timelog(f, name=\"special-name-for-f\")\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(list)\n",
    "\n",
    "    @contextmanager\n",
    "    def timeit(self, name: Hashable, cpu_only=False):\n",
    "        \"\"\"\n",
    "        Records the time elapsed, in seconds, within the context \n",
    "        of this context manager.\n",
    "\n",
    "        Will record the time as `self[name].append(time_elapsed)`\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        name : Hashable\n",
    "            The name (i.e. the identifier) used as the key for\n",
    "            storing the timed code\n",
    "\n",
    "        cpu_only : bool, optional (default=False)\n",
    "            If ``True``, the context manager does not synchronize the\n",
    "            default CUDA device stream\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Invoking this with `cpu_only=False` can incur a one-time \n",
    "        loading time associated with initializing the CUDA\n",
    "        device stream. This delay will occur before the context\n",
    "        is executed and thus will not be present in the recorded \n",
    "        elapsed time. This will not occur if PyTorch has already \n",
    "        initialized a CUDA device (e.g. by putting a model onto \n",
    "        a GPU). \n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        >>> time_log = PyTorchTimeLogger()\n",
    "        >>> with time_log.timeit('event_a', cpu_only=False):\n",
    "        ...     event() # measure time to leave context (seconds)\n",
    "\n",
    "        >>> # the time elapsed within the context is appended\n",
    "        >>> # to `times['event_a']`\"\"\"\n",
    "\n",
    "        if not cpu_only and torch.cuda.is_available():\n",
    "            start_event = torch.cuda.Event(enable_timing=True)\n",
    "            end_event = torch.cuda.Event(enable_timing=True)\n",
    "            start_event.record()  # enqueue start-event\n",
    "            try:\n",
    "                yield name\n",
    "            finally:\n",
    "                end_event.record()  # enqueue stop-event\n",
    "                torch.cuda.synchronize()  # sync/run all events in default device stream\n",
    "\n",
    "                # millisec -> sec\n",
    "                elapsed_time_s = start_event.elapsed_time(end_event) / 1000\n",
    "                self[name].append(elapsed_time_s)\n",
    "        else:\n",
    "            start_time = time()\n",
    "            try:\n",
    "                yield name\n",
    "            finally:\n",
    "                self[name].append(time() - start_time)\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        func: Optional[Callable] = None,\n",
    "        *,\n",
    "        name: Optional[str] = None,\n",
    "        cpu_only: bool = False\n",
    "    ) -> Callable:\n",
    "        \"\"\"Exposes a decorator interface to the timing context.\n",
    "        \n",
    "        Each execution of the decorated function will be timed and logged.\n",
    "        \n",
    "        The decorator can be invoked with or without its named arguments.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        func : Callable\n",
    "            The function to be decorated\n",
    "        \n",
    "        name : Optional[str]\n",
    "            The name associated with the timed event. If `None`, the\n",
    "            name of the decorated function is used.\n",
    "        \n",
    "        cpu_only : bool, optional (default=False)\n",
    "            If True, timing is performed without syncing CUDA events.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        timed_function : Callable\n",
    "    \n",
    "        Examples\n",
    "        --------\n",
    "        Timing function execution with a decorator\n",
    "\n",
    "        >>> timelog = PyTorchTimeLogger()\n",
    "        >>> @timelog  # you can specify `name` and `cpu_only` if you'd like\n",
    "        ... def func():\n",
    "        ...    # Time spent within function body will be logged to\n",
    "        ...    # `timelog[\"func\"]`\n",
    "        ...    pass\n",
    "\n",
    "        Or, you can make a timed function \"on the fly\" with a functional form factor\n",
    "\n",
    "        >>> def f(x): return x\n",
    "        >>> # timing in f will be logged to `timelog[\"special-name-for-f\"]`\n",
    "        >>> timed_f = timelog(f, name=\"special-name-for-f\")\n",
    "        \"\"\"\n",
    "        if name is None:\n",
    "            name = func.__name__\n",
    "\n",
    "        if func is None:\n",
    "            return lambda x: self(x, name=name, cpu_only=cpu_only)\n",
    "\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            with self.timeit(name=name, cpu_only=cpu_only):\n",
    "                return func(*args, **kwargs)\n",
    "\n",
    "        return wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/RobustBench/robustbench\n",
    "from robustbench.data import load_cifar10\n",
    "from robustbench.utils import load_model, clean_accuracy\n",
    "\n",
    "images, labels = load_cifar10(n_examples=50)\n",
    "device = \"cuda\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: robust\n",
      "- Clean Acc: 0.9\n"
     ]
    }
   ],
   "source": [
    "from rai_experiments.models.pretrained import load_model\n",
    "\n",
    "\n",
    "# Load pre-trained model that was trained with standard approach\n",
    "# ckpt, model_name = \"mitll_cifar_nat.pt\", \"standard\"\n",
    "ckpt, model_name = \"mitll_cifar_l2_1_0.pt\", \"robust\"\n",
    "\n",
    "# ckpt_standard = \"mitll_cifar_l2_1_0.pt\"\n",
    "model = load_model(ckpt)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "acc = clean_accuracy(model, images.to(device), labels.to(device))\n",
    "print(\"Model: {}\".format(model_name))\n",
    "print(\"- Clean Acc: {}\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foolbox 3.3.3\n",
      "art 1.12.1\n",
      "rai-toolbox 0.2.1.post1.dev49+g3ae3a80.d20221026\n",
      "torchattacks 3.3.0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# https://github.com/bethgelab/foolbox\n",
    "import foolbox as fb\n",
    "\n",
    "print(\"foolbox %s\" % (fb.__version__))\n",
    "\n",
    "# https://github.com/IBM/adversarial-robustness-toolbox\n",
    "import art\n",
    "import art.attacks.evasion as evasion\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "print(\"art %s\" % (art.__version__))\n",
    "\n",
    "import rai_toolbox\n",
    "from rai_toolbox.perturbations import gradient_ascent, AdditivePerturbation\n",
    "from rai_toolbox.optim import (\n",
    "    L2ProjectedOptim,\n",
    "    ChainedParamTransformingOptimizer,\n",
    "    ClampedGradientOptimizer,\n",
    "    SignedGradientOptim,\n",
    "    ClampedParameterOptimizer,\n",
    "    L2ProjectedOptim\n",
    ")\n",
    "from functools import partial\n",
    "\n",
    "print(\"rai-toolbox %s\" % (rai_toolbox.__version__))\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "# https://github.com/Harry24k/adversarial-attacks-pytorch\n",
    "import torchattacks\n",
    "\n",
    "print(\"torchattacks %s\" % (torchattacks.__version__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.1. Linf\n",
    "### FGSM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: robust\n",
      "- Torchattacks\n",
      "- Robust Acc: 0.0 (81 ms per step)\n",
      "- Foolbox\n",
      "- Robust Acc: 0.0 (104 ms per step)\n",
      "- ART\n",
      "- Robust Acc: 0.0 (84 ms per step)\n",
      "- rai-toolbox\n",
      "- Robust Acc: 0.0 (58 ms per step)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10\n",
    "\n",
    "time_log = PyTorchTimeLogger()\n",
    "\n",
    "print(\"Model: {}\".format(model_name))\n",
    "\n",
    "print(\"- Torchattacks\")\n",
    "\n",
    "atk = torchattacks.FGSM(model, eps=8 / 255)\n",
    "assert not model.training\n",
    "with time_log.timeit(name=\"torch-attack\", cpu_only=False):\n",
    "    adv_images = images\n",
    "    for _ in range(num_steps):\n",
    "        adv_images = atk(adv_images, labels)\n",
    "\n",
    "\n",
    "acc = clean_accuracy(model, adv_images, labels)\n",
    "time, = time_log[\"torch-attack\"]\n",
    "print(\n",
    "    \"- Robust Acc: {} ({} ms per step)\".format(\n",
    "        acc, int(time * 1000 / num_steps)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"- Foolbox\")\n",
    "fmodel = fb.PyTorchModel(model, bounds=(0, 1))\n",
    "atk = fb.attacks.LinfFastGradientAttack(random_start=False)\n",
    "\n",
    "\n",
    "adv_images = images.to(\"cuda:0\")\n",
    "foolbox_labels = labels.to(\"cuda:0\")\n",
    "assert not model.training\n",
    "with time_log.timeit(name=\"Foolbox\", cpu_only=False):\n",
    "    for _ in range(num_steps):\n",
    "        _, adv_images, _ = atk(fmodel, adv_images, foolbox_labels, epsilons=8 / 255)\n",
    "\n",
    "acc = clean_accuracy(model, adv_images, labels)\n",
    "time, = time_log[\"Foolbox\"]\n",
    "print(\n",
    "    \"- Robust Acc: {} ({} ms per step)\".format(\n",
    "        acc, int(time * 1000 / num_steps)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"- ART\")\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    clip_values=(0, 1),\n",
    "    loss=nn.CrossEntropyLoss(),\n",
    "    optimizer=optim.Adam(model.parameters(), lr=0.01),\n",
    "    input_shape=(3, 32, 32),\n",
    "    nb_classes=10,\n",
    ")\n",
    "atk = evasion.FastGradientMethod(\n",
    "    norm=np.inf, batch_size=50, estimator=classifier, eps=8 / 255\n",
    ")\n",
    "\n",
    "\n",
    "adv_images = images.numpy()\n",
    "art_labels = labels.numpy()\n",
    "assert not model.training\n",
    "with time_log.timeit(name=\"ART\", cpu_only=False):\n",
    "    for _ in range(num_steps):\n",
    "        adv_images = atk.generate(adv_images, art_labels)\n",
    "acc = clean_accuracy(model, torch.tensor(adv_images).to(device), labels)\n",
    "\n",
    "time, = time_log[\"ART\"]\n",
    "print(\n",
    "    \"- Robust Acc: {} ({} ms per step)\".format(\n",
    "        acc, int(time * 1000 / num_steps)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"- rai-toolbox\")\n",
    "\n",
    "\n",
    "d_images = images.to(device)\n",
    "d_labels = labels.to(device)\n",
    "\n",
    "pert_model = AdditivePerturbation(d_images)\n",
    "rai_optim = SignedGradientOptim(\n",
    "    lr=8 / 255,\n",
    "    params=pert_model.parameters(),\n",
    ")\n",
    "\n",
    "assert not model.training\n",
    "with time_log.timeit(name=\"rai-toolbox\", cpu_only=False):\n",
    "    adv_images, _ = gradient_ascent(\n",
    "        model=model,\n",
    "        data=d_images,\n",
    "        target=d_labels,\n",
    "        steps=num_steps,\n",
    "        optimizer=rai_optim,\n",
    "        perturbation_model=pert_model,\n",
    "        use_best=False,\n",
    "    )\n",
    "\n",
    "acc = clean_accuracy(model, adv_images, labels)\n",
    "\n",
    "time, = time_log[\"rai-toolbox\"]\n",
    "print(\n",
    "    \"- Robust Acc: {} ({} ms per step)\".format(\n",
    "        acc, int(time * 1000 / num_steps)\n",
    "    )\n",
    ")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: robust\n",
      "- Torchattacks\n",
      "- Robust Acc: 0.44 (80 ms per step)\n",
      "- Foolbox\n",
      "- Robust Acc: 0.44 (82 ms per step)\n",
      "- ART\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951b0d8bd7e949d4852f3f720407a687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Robust Acc: 0.44 (88 ms per step)\n",
      "- rai-toolbox\n",
      "- Robust Acc: 0.44 (58 ms per step)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Model: {}'.format(model_name))\n",
    "num_steps = 10\n",
    "model.eval()\n",
    "time_log = PyTorchTimeLogger()\n",
    "\n",
    "print(\"- Torchattacks\")\n",
    "atk = torchattacks.PGD(model, eps=8/255, alpha=2/255, steps=num_steps, random_start=False)\n",
    "\n",
    "assert not model.training\n",
    "with time_log.timeit(name=\"torch-attack\", cpu_only=False):\n",
    "    adv_images = atk(images, labels)\n",
    "\n",
    "acc = clean_accuracy(model, adv_images, labels)\n",
    "time, = time_log[\"torch-attack\"]\n",
    "print('- Robust Acc: {} ({} ms per step)'.format(acc, int(time * 1000 / num_steps)))\n",
    "\n",
    "print(\"- Foolbox\")\n",
    "fmodel = fb.PyTorchModel(model, bounds=(0, 1))\n",
    "atk = fb.attacks.LinfPGD(abs_stepsize=2/255, steps=num_steps, random_start=False)\n",
    "\n",
    "fb_images = images.to('cuda:0')\n",
    "fb_labels = labels.to('cuda:0')\n",
    "\n",
    "assert not model.training\n",
    "with time_log.timeit(name=\"Foolbox\", cpu_only=False):\n",
    "    _, adv_images, _ = atk(fmodel, fb_images, fb_labels, epsilons=8/255)\n",
    "\n",
    "acc = clean_accuracy(model, adv_images, labels)\n",
    "time, = time_log[\"Foolbox\"]\n",
    "print('- Robust Acc: {} ({} ms per step)'.format(acc, int(time * 1000 / num_steps)))\n",
    "\n",
    "print(\"- ART\")\n",
    "classifier = PyTorchClassifier(model=model, clip_values=(0, 1),\n",
    "                                loss=nn.CrossEntropyLoss(),\n",
    "                                optimizer=optim.Adam(model.parameters(), lr=0.01),\n",
    "                                input_shape=(3, 32, 32), nb_classes=10)\n",
    "atk = evasion.ProjectedGradientDescent(batch_size=50, num_random_init=0,\n",
    "                                        estimator=classifier, eps=8/255,\n",
    "                                        eps_step=2/255, max_iter=num_steps)\n",
    "start = datetime.datetime.now()\n",
    "art_images = images.numpy()\n",
    "art_labels = labels.numpy()\n",
    "\n",
    "assert not model.training\n",
    "with time_log.timeit(name=\"ART\", cpu_only=False):\n",
    "    adv_images = atk.generate(art_images, art_labels)\n",
    "\n",
    "acc = clean_accuracy(model, torch.tensor(adv_images, device=device), labels)\n",
    "time, = time_log[\"ART\"]\n",
    "print('- Robust Acc: {} ({} ms per step)'.format(acc, int(time * 1000 / num_steps)))\n",
    "\n",
    "print(\"- rai-toolbox\")\n",
    "\n",
    "\n",
    "d_images = images.to(device)\n",
    "d_labels = labels.to(device)\n",
    "\n",
    "pert_model = AdditivePerturbation(d_images)\n",
    "rai_optim = ChainedParamTransformingOptimizer(\n",
    "    SignedGradientOptim,\n",
    "    # need smaller epsilon ball to match attack performance\n",
    "    # due to other methods applying an additional clamp to (delta + img)\n",
    "    partial(ClampedParameterOptimizer, clamp_min=-7 / 225, clamp_max=7 / 225),\n",
    "    lr=2 / 255,\n",
    "    params=pert_model.parameters(),\n",
    ")\n",
    "\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "assert not model.training\n",
    "with time_log.timeit(name=\"rai-toolbox\", cpu_only=False):\n",
    "    adv_images, _ = gradient_ascent(\n",
    "        model=model,\n",
    "        data=d_images,\n",
    "        target=d_labels,\n",
    "        steps=num_steps,\n",
    "        optimizer=rai_optim,\n",
    "        perturbation_model=pert_model,\n",
    "        use_best=False,\n",
    "    )\n",
    "    adv_images = torch.clamp(adv_images, 0, 1)\n",
    "\n",
    "acc = clean_accuracy(model, adv_images, labels)\n",
    "\n",
    "time, = time_log[\"rai-toolbox\"]\n",
    "print(\"- Robust Acc: {} ({} ms per step)\".format(acc, int(time * 1000 / num_steps)))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: robust\n",
      "- Torchattacks\n",
      "- Robust Acc: 0.7 (79 ms per step)\n",
      "- Foolbox\n",
      "- Robust Acc: 0.7 (82 ms per step)\n",
      "- ART\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba4ac5cfbf474fe1af93037421c0674e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Robust Acc: 0.7 (90 ms per step)\n",
      "- rai-toolbox\n",
      "- Robust Acc: 0.7 (58 ms per step)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10\n",
    "time_log = PyTorchTimeLogger()\n",
    "\n",
    "print(\"Model: {}\".format(model_name))\n",
    "print(\"- Torchattacks\")\n",
    "atk = torchattacks.PGDL2(\n",
    "    model, eps=128 / 255, alpha=15 / 255, steps=num_steps, random_start=False\n",
    ")\n",
    "with time_log.timeit(name=\"torch-attack\", cpu_only=False):\n",
    "    adv_images = atk(images, labels)\n",
    "\n",
    "acc = clean_accuracy(model, adv_images, labels)\n",
    "\n",
    "time, = time_log[\"torch-attack\"]\n",
    "print(\n",
    "    \"- Robust Acc: {} ({} ms per step)\".format(\n",
    "        acc, int(time * 1000 / num_steps)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"- Foolbox\")\n",
    "fmodel = fb.PyTorchModel(model, bounds=(0, 1))\n",
    "atk = fb.attacks.L2PGD(abs_stepsize=15 / 255, steps=num_steps, random_start=False)\n",
    "fb_images = images.to(\"cuda:0\")\n",
    "fb_labels = labels.to(\"cuda:0\")\n",
    "with time_log.timeit(name=\"Foolbox\", cpu_only=False):\n",
    "    _, adv_images, _ = atk(fmodel, fb_images, fb_labels, epsilons=128 / 255)\n",
    "\n",
    "acc = clean_accuracy(model, adv_images, labels)\n",
    "\n",
    "time, = time_log[\"Foolbox\"]\n",
    "print(\n",
    "    \"- Robust Acc: {} ({} ms per step)\".format(\n",
    "        acc, int(time * 1000 / num_steps)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"- ART\")\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    clip_values=(0, 1),\n",
    "    loss=nn.CrossEntropyLoss(),\n",
    "    optimizer=optim.Adam(model.parameters(), lr=0.01),\n",
    "    input_shape=(3, 32, 32),\n",
    "    nb_classes=10,\n",
    ")\n",
    "atk = evasion.ProjectedGradientDescent(\n",
    "    batch_size=50,\n",
    "    num_random_init=0,\n",
    "    norm=2,\n",
    "    estimator=classifier,\n",
    "    eps=128 / 255,\n",
    "    eps_step=15 / 255,\n",
    "    max_iter=num_steps,\n",
    ")\n",
    "\n",
    "art_imgs = images.numpy()\n",
    "art_lbls = labels.numpy()\n",
    "\n",
    "with time_log.timeit(name=\"ART\", cpu_only=False):\n",
    "    adv_images = atk.generate(art_imgs, art_lbls)\n",
    "\n",
    "acc = clean_accuracy(model, torch.tensor(adv_images, device=device), labels)\n",
    "\n",
    "time, = time_log[\"ART\"]\n",
    "print(\n",
    "    \"- Robust Acc: {} ({} ms per step)\".format(\n",
    "        acc, int(time * 1000 / num_steps)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"- rai-toolbox\")\n",
    "\n",
    "d_images = images.to(device)\n",
    "d_labels = labels.to(device)\n",
    "\n",
    "pert_model = AdditivePerturbation(d_images)\n",
    "rai_optim = L2ProjectedOptim(\n",
    "    lr=15 / 255,\n",
    "    epsilon=128 / 255,\n",
    "    params=pert_model.parameters(),\n",
    ")\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "with time_log.timeit(name=\"rai-toolbox\", cpu_only=False):\n",
    "    adv_images, _ = gradient_ascent(\n",
    "        model=model,\n",
    "        data=d_images,\n",
    "        target=d_labels,\n",
    "        steps=num_steps,\n",
    "        optimizer=rai_optim,\n",
    "        perturbation_model=pert_model,\n",
    "        use_best=False,\n",
    "    )\n",
    "    adv_images = torch.clamp(adv_images, 0, 1)\n",
    "\n",
    "acc = clean_accuracy(model, adv_images, labels)\n",
    "\n",
    "time, = time_log[\"rai-toolbox\"]\n",
    "print(\"- Robust Acc: {} ({} ms per step)\".format(acc, int(time * 1000 / num_steps)))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "FSGM, Model: standard\n",
    "- Torchattacks\n",
    "  - Robust Acc: 0.0 (82 ms per step)\n",
    "- Foolbox\n",
    "  - Robust Acc: 0.0 (105 ms per step)\n",
    "- ART\n",
    "  - Robust Acc: 0.0 (83 ms per step)\n",
    "- rai-toolbox\n",
    "  - Robust Acc: 0.0 (58 ms per step)\n",
    "\n",
    "\n",
    "LinfPGD, Model: standard\n",
    "- Torchattacks\n",
    "  - Robust Acc: 0.0 (81 ms per step)\n",
    "- Foolbox\n",
    "  - Robust Acc: 0.0 (82 ms per step)\n",
    "- ART\n",
    "  - Robust Acc: 0.0 (89 ms per step)\n",
    "- rai-toolbox\n",
    "  - Robust Acc: 0.0 (58 ms per step)\n",
    "\n",
    "\n",
    "L2PGD, Model: standard\n",
    "- Torchattacks\n",
    "  - Robust Acc: 0.02 (79 ms per step)\n",
    "- Foolbox\n",
    "  - Robust Acc: 0.02 (82 ms per step)\n",
    "- ART\n",
    "  - Robust Acc: 0.02 (89 ms per step)\n",
    "- rai-toolbox\n",
    "  - Robust Acc: 0.02 (58 ms per step)\n",
    "\n",
    "\n",
    "FGSM, Model: robust\n",
    "- Torchattacks\n",
    "  - Robust Acc: 0.0 (81 ms per step)\n",
    "- Foolbox\n",
    "  - Robust Acc: 0.0 (105 ms per step)\n",
    "- ART\n",
    "  - Robust Acc: 0.0 (84 ms per step)\n",
    "- rai-toolbox\n",
    "  - Robust Acc: 0.0 (58 ms per step)\n",
    "\n",
    "LinfPGD, Model: robust\n",
    "- Torchattacks\n",
    "  - Robust Acc: 0.44 (79 ms per step)\n",
    "- Foolbox\n",
    "  - Robust Acc: 0.44 (82 ms per step)\n",
    "- ART\n",
    "  - Robust Acc: 0.44 (90 ms per step)\n",
    "- rai-toolbox\n",
    "  - Robust Acc: 0.44 (58 ms per step)\n",
    "\n",
    "L2PGD, Model: robust\n",
    "- Torchattacks\n",
    "  - Robust Acc: 0.7 (81 ms per step)\n",
    "- Foolbox\n",
    "  - Robust Acc: 0.7 (82 ms per step)\n",
    "- ART\n",
    "  - Robust Acc: 0.7 (89 ms per step)\n",
    "- rai-toolbox\n",
    "  - Robust Acc: 0.7 (58 ms per step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Attack       | Package        | Model: Madry-Robust |\n",
    "| :-----------:| -------------  |     -------------   |\n",
    "| FGSM (Linf)  | rai-toolbox    |  **58 ms** (0%) |\n",
    "|              | Torchattacks   |  81 ms (0%)       |\n",
    "|              | Foolbox        |  105 ms (0%)      |\n",
    "|              | ART            |  83 ms (0%)       |\n",
    "| PGD (Linf)   | rai-toolbox    |  **58 ms** (44%) |\n",
    "|              | Torchattacks   |  79 ms (44%)       |\n",
    "|              | Foolbox        |  82 ms (44%)      |\n",
    "|              | ART            |  90 ms (44%)       |\n",
    "| PGD (L2)   | rai-toolbox    |  **58 ms** (70%) |\n",
    "|              | Torchattacks   |  81 ms (70%)       |\n",
    "|              | Foolbox        |  82 ms (70%)      |\n",
    "|              | ART            |  89 ms (70%)       |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('benchmark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8654d50f773c0a3ed5ea784e739c6b14bda1a4c249d24cb0038266dd69cea3d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
